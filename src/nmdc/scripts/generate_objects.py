#!/usr/bin/python

import sys
import json
import os
import hashlib
import argparse


def get_md5(fn):
    md5f = fn + '.md5'
    if os.path.exists(md5f):
        with open(md5f) as f:
            md5 = f.read().rstrip()
    else:
        md5 = hashlib.md5(open(fn, 'rb').read()).hexdigest()
        with open(md5f, 'w') as f:
            f.write(md5)
            f.write('\n')
    return md5

def gen_id(gid, git_url, start_date, end_date):
    txt = "{}\n{}\n{}\n{}\n".format(gid, git_url, start_date, end_date)
    print("hash: "+txt)
    md5hash = hashlib.md5(txt.encode('utf-8')).hexdigest()
    print(md5hash)
    return 'nmdc:{}'.format(md5hash)

def gen_data_objects(fpath, url, name, des, gid):
        md5 = get_md5(fpath)
        fmeta = os.stat(fpath)

        obj = {
           'id': 'nmdc:{}'.format(md5),
           'name': '{}_{}'.format(gid, name),
           'description': '{} for {}'.format(des, gid),
           'md5_checksum': md5,
           'url': url,
           'file_size_bytes': fmeta.st_size
        }
        return obj

def main():
    parser = argparse.ArgumentParser(description='Generate metadata files.')
    parser.add_argument('--activityid', metavar='activityid', default=False,
                        help='optional: activity id (autogenerated if not provided)')
    parser.add_argument('--outputs', metavar='outputs', nargs='+',
                        help='output files and their description')
    parser.add_argument('--inputs', metavar='inputs', nargs='+',
                        help='inputs files and their description')
    parser.add_argument('--type', dest='type', help='analysis type', required=True)
    parser.add_argument('--id', dest='id', help='was_informed by id', required=False)
    parser.add_argument('--name', dest='name', help='name for activity', required=True)
    parser.add_argument('--start', dest='start', help='start time', required=True)
    parser.add_argument('--end', dest='end', help='end tim', required=True)
    parser.add_argument('--resource', dest='resource', help='compute resource name', required=True)
    parser.add_argument('--giturl', dest='giturl', help='git url for WDL', required=True)
    parser.add_argument('--url', dest='url', help='base url for file urls', required=True)
    parser.add_argument('--part', dest='part', help='part of', required=False)
    parser.add_argument('--extra', dest='extra', help='filename with extra metadata')
    args = parser.parse_args()
    print(args)

    ins = []
    if args.inputs:
        for inp in args.inputs:
            ins.append('nmdc:{}'.format(get_md5(inp)))
    outs = []
    # Generate data objects
    data_objects = []
    if args.outputs:
        item_list = args.outputs
    else:
        item_list = []
    for i in range(0, len(item_list),3):
        fn = item_list[i]
        des = item_list[i+1]
        name = item_list[i+2]
        url = '%s%s' % (args.url, fn.split('/')[-1])
        obj = gen_data_objects(fn, url, name, des, args.id)
        data_objects.append(obj)
        outs.append(obj['id'])
    if args.activityid:
        activity_id = args.activityid
    else:
        activity_id = gen_id(args.id, args.giturl, args.start, args.end)
    meta = {
            "id": activity_id,
            "name": args.name,
            "started_at_time": args.start,
            "ended_at_time": args.end,
            "type": args.type,
            "execution_resource": args.resource,
            "git_url": args.giturl,
            "has_input": ins,
            "has_output": outs,
    }
    if args.part:
       meta['part_of'] = args.part
    if args.id:
       meta["was_informed_by"] = args.id
    if args.extra:
       extra = json.loads(open(args.extra).read())
       for k in extra.keys():
          meta[k] = extra[k]

    print(json.dumps(meta, indent=2))
    with open('activity.json', 'w') as f:
        f.write(json.dumps(meta, indent=2)+'\n')
    print(json.dumps(data_objects, indent=2))
    with open('data_objects.json', 'w') as f:
        f.write(json.dumps(data_objects, indent=2)+'\n')


if __name__ == '__main__':
    main()

